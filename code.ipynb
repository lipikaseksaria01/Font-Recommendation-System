{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1z41PqPqeAsb7_H-emcf1ARiHPEWr7XZG","authorship_tag":"ABX9TyO5/1hFopFaOjOM1Sw2tE0I"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install fonttools"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2kzppiPtHj6-","executionInfo":{"status":"ok","timestamp":1707050550277,"user_tz":-330,"elapsed":4734,"user":{"displayName":"Rushabh Shah","userId":"13766780658269780582"}},"outputId":"dd989ea1-3233-49c3-ef3e-498d7a50212e"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: fonttools in /usr/local/lib/python3.10/dist-packages (4.47.2)\n"]}]},{"cell_type":"code","execution_count":80,"metadata":{"id":"tmpohTT2DtJv","executionInfo":{"status":"ok","timestamp":1707054327990,"user_tz":-330,"elapsed":2,"user":{"displayName":"Rushabh Shah","userId":"13766780658269780582"}}},"outputs":[],"source":["from gensim.models import Word2Vec\n","from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, concatenate\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","import numpy as np\n","import os, random\n","import tensorflow as tf"]},{"cell_type":"code","source":["from ttfquery import describe\n","from google.colab import drive\n","drive.mount('/content/drive')\n","!unzip /content/drive/MyDrive/fonts.zip -d \"/content/drive/My Drive/fonts\""],"metadata":{"id":"H9VoQa18GP6O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 1: Load and preprocess font files\n","font_directory = \"/content/drive/My Drive/fonts/Fonts\"\n","font_files = [os.path.join(font_directory, file) for file in os.listdir(font_directory) if file.endswith(\".ttf\")]\n","num_fonts = len(font_files)"],"metadata":{"id":"9oy2cnYKGZ8o","executionInfo":{"status":"ok","timestamp":1707055782715,"user_tz":-330,"elapsed":436,"user":{"displayName":"Rushabh Shah","userId":"13766780658269780582"}}},"execution_count":136,"outputs":[]},{"cell_type":"code","source":["from fontTools.ttLib import TTFont\n","\n","def extract_text_from_ttf(font_file):\n","    try:\n","        # Open the TrueType font file\n","        font = TTFont(font_file)\n","\n","        # Extract the font family, subfamily, and full name\n","        font_family = font['name'].getName(1, 3, 1, 0x409).string.decode('utf-8')\n","        font_subfamily = font['name'].getName(2, 3, 1, 0x409).string.decode('utf-8')\n","        full_name = font['name'].getName(4, 3, 1, 0x409).string.decode('utf-8')\n","\n","        # Construct a simple text string from font metadata\n","        text_data = f\"Font Family: {font_family}\\nFont Subfamily: {font_subfamily}\\nFull Name: {full_name}\"\n","\n","        return text_data\n","\n","    except Exception as e:\n","        print(f\"Error extracting text from {font_file}: {str(e)}\")\n","        return \"\""],"metadata":{"id":"tQoy4HPHH3mu","executionInfo":{"status":"ok","timestamp":1707055498298,"user_tz":-330,"elapsed":2,"user":{"displayName":"Rushabh Shah","userId":"13766780658269780582"}}},"execution_count":124,"outputs":[]},{"cell_type":"code","source":["# Step 2: Train Word2Vec model on font data\n","sentences = []\n","\n","for font_file in font_files:\n","    # You may need to extract relevant text data from the font file\n","    # Replace the following line with the actual code to extract text from .ttf files\n","    text_data = extract_text_from_ttf(font_file)\n","\n","    # Tokenize text into sentences\n","    sentences.extend([sentence.split() for sentence in text_data])\n","# Train Word2Vec model\n","word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n","word2vec_model.train(sentences, total_examples=len(sentences), epochs=10)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jGEpxP-WHGzO","executionInfo":{"status":"ok","timestamp":1707056891478,"user_tz":-330,"elapsed":7093,"user":{"displayName":"Rushabh Shah","userId":"13766780658269780582"}},"outputId":"8f20390e-59b4-4719-c86d-d6893adcdb01"},"execution_count":145,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"]},{"output_type":"execute_result","data":{"text/plain":["(313516, 1491670)"]},"metadata":{},"execution_count":145}]},{"cell_type":"code","source":["# Get the vocabulary from the Word2Vec model\n","vocabulary = list(word2vec_model.wv.key_to_index.keys())\n","\n","# Create a mapping from font to index\n","font_to_index = {font: i for i, font in enumerate(font_files)}\n","\n","# Initialize the embedding matrix with zeros\n","embedding_size = word2vec_model.vector_size\n","embedding_matrix = np.zeros((len(font_files), embedding_size))\n","\n","# Populate the embedding matrix with Word2Vec embeddings for each font\n","for i, font in enumerate(font_files):\n","    # If the font is in the Word2Vec vocabulary, use its embedding\n","    if font in vocabulary:\n","        embedding_matrix[i] = word2vec_model.wv[font]"],"metadata":{"id":"SSOca0LGhUzZ","executionInfo":{"status":"ok","timestamp":1707057058219,"user_tz":-330,"elapsed":1,"user":{"displayName":"Rushabh Shah","userId":"13766780658269780582"}}},"execution_count":149,"outputs":[]},{"cell_type":"code","source":["len(embedding_matrix)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3xACKhNahXEn","executionInfo":{"status":"ok","timestamp":1707057064599,"user_tz":-330,"elapsed":4,"user":{"displayName":"Rushabh Shah","userId":"13766780658269780582"}},"outputId":"991793c4-6adb-4952-e689-2e47694b2e75"},"execution_count":150,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1460"]},"metadata":{},"execution_count":150}]},{"cell_type":"code","source":["# Step 1: Create pairs of fonts and labels\n","def create_font_pairs_and_labels(num_pairs):\n","    font_pairs = []\n","    contrast_labels = []\n","    theme_labels = []\n","\n","    for _ in range(num_pairs):\n","        font_a, font_b = random.sample(font_files, 2)\n","\n","        # Replace these with your actual logic for extracting text from .ttf files\n","        text_a = f\"Text from {font_a}\"\n","        text_b = f\"Text from {font_b}\"\n","\n","        # You might want to improve this labeling logic based on your dataset\n","        contrast_label = 1 if random.random() > 0.5 else 0  # Randomly label for contrast\n","        theme_label = 1 if text_a == text_b else 0  # Label based on some criteria (e.g., same theme)\n","\n","        font_pairs.append((font_a, font_b))\n","        contrast_labels.append(contrast_label)\n","        theme_labels.append(theme_label)\n","\n","    return font_pairs, contrast_labels, theme_labels\n","\n","# Step 2: Use the function to create font pairs and labels\n","num_pairs = 1000  # Adjust based on your dataset size\n","font_pairs, contrast_labels, theme_labels = create_font_pairs_and_labels(num_pairs)"],"metadata":{"id":"EdQyutPeZT0A","executionInfo":{"status":"ok","timestamp":1707057098552,"user_tz":-330,"elapsed":408,"user":{"displayName":"Rushabh Shah","userId":"13766780658269780582"}}},"execution_count":151,"outputs":[]},{"cell_type":"code","source":["# Convert labels to numpy arrays\n","contrast_labels = np.array(contrast_labels)\n","theme_labels = np.array(theme_labels)\n","\n","# Convert font pairs to separate lists\n","font_pair_a, font_pair_b = zip(*font_pairs)\n","font_pair_a = list(font_pair_a)\n","font_pair_b = list(font_pair_b)\n","\n","# Convert font pairs to indices (numbers) because Embedding layer expects numerical inputs\n","font_to_index = {font: i for i, font in enumerate(font_files)}\n","font_pair_a_indices = [font_to_index[font] for font in font_pair_a]\n","font_pair_b_indices = [font_to_index[font] for font in font_pair_b]\n","font_pair_a_indices = tf.cast(font_pair_a_indices, tf.int32)\n","font_pair_b_indices = tf.cast(font_pair_b_indices, tf.int32)"],"metadata":{"id":"2WPldtr1bbtV","executionInfo":{"status":"ok","timestamp":1707057102195,"user_tz":-330,"elapsed":1,"user":{"displayName":"Rushabh Shah","userId":"13766780658269780582"}}},"execution_count":152,"outputs":[]},{"cell_type":"code","source":["# Step 3: Create a Siamese network with pre-trained Word2Vec embeddings\n","input_a = tf.keras.layers.Input(shape=(1,), name='input_a')\n","input_b = tf.keras.layers.Input(shape=(1,), name='input_b')\n","\n","embedding_layer = tf.keras.layers.Embedding(num_fonts, embedding_size, weights=[embedding_matrix], trainable=False)\n","\n","embedding_a = embedding_layer(input_a)\n","embedding_b = embedding_layer(input_b)\n","\n","flattened_a = tf.keras.layers.Flatten()(embedding_a)\n","flattened_b = tf.keras.layers.Flatten()(embedding_b)\n","\n","merged = tf.keras.layers.concatenate([flattened_a, flattened_b])\n","\n","dense_layer_1 = tf.keras.layers.Dense(128, activation='relu')(merged)\n","dense_layer_2 = tf.keras.layers.Dense(64, activation='relu')(dense_layer_1)\n","\n","contrast_output = tf.keras.layers.Dense(1, activation='sigmoid', name='contrast_output')(dense_layer_2)\n","theme_output = tf.keras.layers.Dense(1, activation='sigmoid', name='theme_output')(dense_layer_2)\n","\n","siamese_model = tf.keras.models.Model(inputs=[input_a, input_b], outputs=[contrast_output, theme_output])\n","\n","# Print the model summary for verification\n","siamese_model.summary()\n","\n","# Compile the model\n","siamese_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Step 4: Train the model\n","siamese_model.fit([font_pair_a_indices, font_pair_b_indices], [contrast_labels, theme_labels], epochs=10, batch_size=32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mx49RHbMWYdx","executionInfo":{"status":"ok","timestamp":1707057106283,"user_tz":-330,"elapsed":1515,"user":{"displayName":"Rushabh Shah","userId":"13766780658269780582"}},"outputId":"82791abe-bc62-4d9d-ce5b-34770a62627b"},"execution_count":153,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_34\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_a (InputLayer)        [(None, 1)]                  0         []                            \n","                                                                                                  \n"," input_b (InputLayer)        [(None, 1)]                  0         []                            \n","                                                                                                  \n"," embedding_37 (Embedding)    (None, 1, 100)               146000    ['input_a[0][0]',             \n","                                                                     'input_b[0][0]']             \n","                                                                                                  \n"," flatten_68 (Flatten)        (None, 100)                  0         ['embedding_37[0][0]']        \n","                                                                                                  \n"," flatten_69 (Flatten)        (None, 100)                  0         ['embedding_37[1][0]']        \n","                                                                                                  \n"," concatenate_34 (Concatenat  (None, 200)                  0         ['flatten_68[0][0]',          \n"," e)                                                                  'flatten_69[0][0]']          \n","                                                                                                  \n"," dense_68 (Dense)            (None, 128)                  25728     ['concatenate_34[0][0]']      \n","                                                                                                  \n"," dense_69 (Dense)            (None, 64)                   8256      ['dense_68[0][0]']            \n","                                                                                                  \n"," contrast_output (Dense)     (None, 1)                    65        ['dense_69[0][0]']            \n","                                                                                                  \n"," theme_output (Dense)        (None, 1)                    65        ['dense_69[0][0]']            \n","                                                                                                  \n","==================================================================================================\n","Total params: 180114 (703.57 KB)\n","Trainable params: 34114 (133.26 KB)\n","Non-trainable params: 146000 (570.31 KB)\n","__________________________________________________________________________________________________\n","Epoch 1/10\n","32/32 [==============================] - 1s 2ms/step - loss: 1.3788 - contrast_output_loss: 0.6932 - theme_output_loss: 0.6856 - contrast_output_accuracy: 0.5090 - theme_output_accuracy: 1.0000\n","Epoch 2/10\n","32/32 [==============================] - 0s 2ms/step - loss: 1.3630 - contrast_output_loss: 0.6931 - theme_output_loss: 0.6699 - contrast_output_accuracy: 0.5090 - theme_output_accuracy: 1.0000\n","Epoch 3/10\n","32/32 [==============================] - 0s 2ms/step - loss: 1.3477 - contrast_output_loss: 0.6931 - theme_output_loss: 0.6546 - contrast_output_accuracy: 0.5090 - theme_output_accuracy: 1.0000\n","Epoch 4/10\n","32/32 [==============================] - 0s 2ms/step - loss: 1.3327 - contrast_output_loss: 0.6931 - theme_output_loss: 0.6397 - contrast_output_accuracy: 0.5090 - theme_output_accuracy: 1.0000\n","Epoch 5/10\n","32/32 [==============================] - 0s 2ms/step - loss: 1.3181 - contrast_output_loss: 0.6931 - theme_output_loss: 0.6251 - contrast_output_accuracy: 0.5090 - theme_output_accuracy: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 0s 2ms/step - loss: 1.3039 - contrast_output_loss: 0.6931 - theme_output_loss: 0.6108 - contrast_output_accuracy: 0.5090 - theme_output_accuracy: 1.0000\n","Epoch 7/10\n","32/32 [==============================] - 0s 2ms/step - loss: 1.2900 - contrast_output_loss: 0.6931 - theme_output_loss: 0.5970 - contrast_output_accuracy: 0.5090 - theme_output_accuracy: 1.0000\n","Epoch 8/10\n","32/32 [==============================] - 0s 2ms/step - loss: 1.2765 - contrast_output_loss: 0.6931 - theme_output_loss: 0.5834 - contrast_output_accuracy: 0.5090 - theme_output_accuracy: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 0s 2ms/step - loss: 1.2633 - contrast_output_loss: 0.6930 - theme_output_loss: 0.5702 - contrast_output_accuracy: 0.5090 - theme_output_accuracy: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 0s 2ms/step - loss: 1.2504 - contrast_output_loss: 0.6930 - theme_output_loss: 0.5573 - contrast_output_accuracy: 0.5090 - theme_output_accuracy: 1.0000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7f41142f7190>"]},"metadata":{},"execution_count":153}]},{"cell_type":"code","source":["# Create a mapping from font to index\n","font_to_index = {font: i for i, font in enumerate(font_files)}\n","\n","# Create a mapping from index to font\n","index_to_font = {i: font for i, font in enumerate(font_files)}\n","\n","def recommend_fonts(siamese_model, font_to_index, base_font, num_recommendations=5):\n","    # Find the index of the base font\n","    base_font_index = font_to_index.get(base_font, 0)\n","\n","    # Create input pairs with the base font\n","    font_pair_a_recommend = [base_font_index] * len(font_to_index)\n","    font_pair_b_recommend = list(range(len(font_to_index)))\n","\n","    # Make predictions\n","    recommendations = siamese_model.predict([np.array(font_pair_a_recommend), np.array(font_pair_b_recommend)])\n","\n","    # Extract contrast and theme scores\n","    contrast_scores = recommendations[0].flatten()\n","    theme_scores = recommendations[1].flatten()\n","\n","    # Combine scores into a single similarity score (you might adjust this based on your requirements)\n","    similarity_scores = 0.5 * contrast_scores + 0.5 * theme_scores\n","\n","    # Get indices of top recommendations\n","    top_indices = np.argsort(similarity_scores)[::-1][:num_recommendations]\n","\n","    # Get recommended fonts\n","    recommended_fonts = [index_to_font[i] for i in top_indices]\n","\n","    return recommended_fonts\n","\n","# Example usage:\n","base_font = \"Ac.ttf\"  # Replace with your desired base font\n","recommended_fonts = recommend_fonts(siamese_model, font_to_index, base_font)\n","\n","print(f\"Recommended fonts for {base_font}:\")\n","for i, font in enumerate(recommended_fonts, start=1):\n","    print(f\"{i}. {font}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Y-uF9QKelg5","executionInfo":{"status":"ok","timestamp":1707057110843,"user_tz":-330,"elapsed":422,"user":{"displayName":"Rushabh Shah","userId":"13766780658269780582"}},"outputId":"e7dcdfdf-c34a-4fd1-9ac2-39968828afef"},"execution_count":154,"outputs":[{"output_type":"stream","name":"stdout","text":["46/46 [==============================] - 0s 998us/step\n","Recommended fonts for Ac.ttf:\n","1. /content/drive/My Drive/fonts/Fonts/FreeUniversal-Regular.ttf\n","2. /content/drive/My Drive/fonts/Fonts/Colors Of Autumn.ttf\n","3. /content/drive/My Drive/fonts/Fonts/CursiveSans.ttf\n","4. /content/drive/My Drive/fonts/Fonts/ARDELANEY.ttf\n","5. /content/drive/My Drive/fonts/Fonts/Denise_Handwriting.ttf\n"]}]}]}